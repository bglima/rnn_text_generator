{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lib download\n",
    "\n",
    "Used lib [textgenrnn](https://github.com/minimaxir/textgenrnn) is avaliable to be installed via pip install, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textgenrnn in c:\\python36\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: h5py in c:\\python36\\lib\\site-packages (from textgenrnn) (2.8.0)\n",
      "Requirement already satisfied: keras>=2.1.5 in c:\\python36\\lib\\site-packages (from textgenrnn) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\python36\\lib\\site-packages (from textgenrnn) (0.19.1)\n",
      "Requirement already satisfied: six in c:\\python36\\lib\\site-packages (from h5py->textgenrnn) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\python36\\lib\\site-packages (from h5py->textgenrnn) (1.14.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\python36\\lib\\site-packages (from keras>=2.1.5->textgenrnn) (1.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\python36\\lib\\site-packages (from keras>=2.1.5->textgenrnn) (3.13)\n",
      "Requirement already satisfied: keras-applications==1.0.2 in c:\\python36\\lib\\site-packages (from keras>=2.1.5->textgenrnn) (1.0.2)\n",
      "Requirement already satisfied: keras-preprocessing==1.0.1 in c:\\python36\\lib\\site-packages (from keras>=2.1.5->textgenrnn) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install textgenrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Importing lib and testing sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "I don't like this before you can see the top of the first time in the same card and he was a serious story?\n",
      "\n",
      "I don't like the state of the state of the same time in the first time in the same card show and all of the states of the state of the state of the state of the store to the state of the star on the state of the same series of the state of the world in the same to start and the subreddit is on the\n",
      "\n",
      "I don't like this on the same time to start a stranger to the state of the story of the world is a life and when I was a good country to the student in the state in the first time in the sidewalk because they don't have a stream on the story of the state of the streets and the most picture of the \n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "I don't like blowing a parador on the united track for the first time. I didn't know what to do what the destroyers?\n",
      "\n",
      "I don't like the position of a trailer for my boyfriend [21F] with me on an all of them and who looks like the denies are missing the anime games to do it?\n",
      "\n",
      "I don't like this when I want to be left because of parents is a concept where some possible stores are a stranger and have a bad game to the U.S. players want to take another person.\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "I don't like you have annoyed should be hand the cool Evolution so should not be please.\n",
      "\n",
      "I don't like to go, incashed\n",
      "\n",
      "I don't like time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn\n",
    "\n",
    "textgen = textgenrnn()\n",
    "textgen.generate_samples(prefix=\"I don't like \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a new model\n",
    "\n",
    "Following model is based on the book *Dom Casmurro* from Machado de Assis. The book as a .txt file was found at his [link](https://archive.org/stream/DomCasmurro/Dom%20Casmurro_djvu.txt). It was necessery to remove blank lines, task we did automatically using Notepad++. We also changed EOL character to match Linux pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,756 texts collected.\n",
      "Training new model w/ 3-layer, 128-cell Bidirectional LSTMs\n",
      "Training on 70,406 word sequences.\n",
      "Epoch 1/15\n",
      "68/68 [==============================] - 51s 746ms/step - loss: 6.6194 - val_loss: 5.9087\n",
      "Epoch 2/15\n",
      "68/68 [==============================] - 46s 670ms/step - loss: 5.2259 - val_loss: 5.4421\n",
      "Epoch 3/15\n",
      "68/68 [==============================] - 45s 660ms/step - loss: 4.8003 - val_loss: 5.4248\n",
      "Epoch 4/15\n",
      "68/68 [==============================] - 43s 628ms/step - loss: 4.4567 - val_loss: 5.5202\n",
      "Epoch 5/15\n",
      "68/68 [==============================] - 43s 628ms/step - loss: 4.1259 - val_loss: 5.6007\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "nao me lembra .\n",
      "\n",
      "nao , e que eu nao sei que o que\n",
      "\n",
      "nao , bentinho , e que eu nao sabia ,\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "nao , bentinho ; mas eu ihe deu ; a\n",
      "\n",
      "vez que era o padre cabral , e o que nao me fez lembrar a\n",
      "\n",
      "que nao , como se alguem , o que eu\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "com alguma vez a bulha , a dotes que tal\n",
      "\n",
      "padre sobre uma bela edigao . as devotas sao nada ,\n",
      "\n",
      "olhos no quarto ? protonotario . mas de repente , onde me assustou\n",
      "\n",
      "Epoch 6/15\n",
      "68/68 [==============================] - 46s 669ms/step - loss: 3.8037 - val_loss: 5.7301\n",
      "Epoch 7/15\n",
      "68/68 [==============================] - 43s 631ms/step - loss: 3.4915 - val_loss: 5.7890\n",
      "Epoch 8/15\n",
      "68/68 [==============================] - 43s 628ms/step - loss: 3.1923 - val_loss: 5.9813\n",
      "Epoch 9/15\n",
      "68/68 [==============================] - 44s 651ms/step - loss: 2.9309 - val_loss: 6.0306\n",
      "Epoch 10/15\n",
      "68/68 [==============================] - 44s 640ms/step - loss: 2.7165 - val_loss: 6.1320\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "nao , bentinho ; eu nao posso ser padre .\n",
      "\n",
      "nao , bentinho ; eu nao me atrevo nem peraltas na vizinhanga , nem\n",
      "\n",
      "nao , bentinho , mas eu nao me atrevo nem os\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "era muito bom .\n",
      "\n",
      "o que e que eu digo .\n",
      "\n",
      "que e , nao se negando o meu quarto ,\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "do desespero , ouvi - se e julga - me , disse a mulher e os\n",
      "\n",
      "nao tocava logo que nada ; ele nessa coisa . quantas comercio ,\n",
      "\n",
      "mesmas , quando os tarde e me invejassem em mim . e esse arvorecer esbeltas :\n",
      "\n",
      "Epoch 11/15\n",
      "68/68 [==============================] - 45s 658ms/step - loss: 2.5354 - val_loss: 6.2264\n",
      "Epoch 12/15\n",
      "68/68 [==============================] - 45s 668ms/step - loss: 2.3893 - val_loss: 6.2391\n",
      "Epoch 13/15\n",
      "68/68 [==============================] - 45s 657ms/step - loss: 2.2752 - val_loss: 6.2643\n",
      "Epoch 14/15\n",
      "68/68 [==============================] - 41s 598ms/step - loss: 2.1787 - val_loss: 6.2817\n",
      "Epoch 15/15\n",
      "68/68 [==============================] - 43s 627ms/step - loss: 2.1121 - val_loss: 6.3224\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "que eu sentisse nada , e o meu amigo .\n",
      "\n",
      "nao , bentinho ; estou pronto a capitu , mas eu\n",
      "\n",
      "que me dispos por mim , e nao me acudiram ,\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "nao e preciso dizer o resto . nao obstante vocagao ,\n",
      "\n",
      "que ? . . . . . \" . \" .\n",
      "\n",
      "louga , e pedfamos , ate que a culpa de\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "lindfssimo ! no segundo desprezo ! so ihe ouvi tudo a fim havia . mas vendo que eles tenho acaso tudo cedo esse filho e antes . nao quero dizer que tudo me ha de pecado ; tinha quase tao sair do com palavras um\n",
      "\n",
      "fazendola e diga - se devemos tudo se era velho de casa , nao esposa mais nada . mas disse que ela nao\n",
      "\n",
      "liso , folheava que houvesse , como realmente , e ele a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_name = \"datasets/dom_casmurro.txt\"\n",
    "\n",
    "model_1 = textgenrnn(name=\"models/dom_casmurro\")\n",
    "\n",
    "model_cfg = {\n",
    "    'word_level': True,# set to True if want to train a word-level model (requires more data and smaller max_length)\n",
    "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
    "    'rnn_layers': 3,   # number of LSTM layers (>2 recommended)\n",
    "    'rnn_bidirectional': True,   # consider text both forwards and backward, can give a training boost\n",
    "    'max_length': 10,  # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
    "    'max_words': 2000, # maximum number of words to model; the rest will be ignored (word-level model only)\n",
    "}\n",
    "\n",
    "train_cfg = {\n",
    "    'line_delimited': False,   # set to True if each text has its own line in the source file\n",
    "    'num_epochs': 15,  # set higher to train the model for longer\n",
    "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
    "    'train_size': 0.8, # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
    "    'dropout': 0.2,     # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
    "    'validation': True,# If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
    "    'is_csv': False     # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
    "}\n",
    "\n",
    "model_1.train_from_file(\n",
    "                        file_path=file_name,\n",
    "                        new_model=True,\n",
    "                        num_epochs=train_cfg['num_epochs'],\n",
    "                        gen_epochs=train_cfg['gen_epochs'],\n",
    "                        batch_size=1024,\n",
    "                        train_size=train_cfg['train_size'],\n",
    "                        dropout=train_cfg['dropout'],\n",
    "                        validation=train_cfg['validation'],\n",
    "                        is_csv=train_cfg['is_csv'],\n",
    "                        rnn_layers=model_cfg['rnn_layers'],\n",
    "                        rnn_size=model_cfg['rnn_size'],\n",
    "                        rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
    "                        max_length=model_cfg['max_length'],\n",
    "                        dim_embeddings=100,\n",
    "                        word_level=model_cfg['word_level'],\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing text generation with our model\n",
    "\n",
    "Let's test text generation with some of the protagonists names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generating text with \"Capitu \" as prefix...\n",
      "capitu , bentinho ?\n",
      "\n",
      "capitu nao me lembra bem .\n",
      "\n",
      "capitu , acharam - se a primeira vez que nao\n",
      "\n",
      "capitu .\n",
      "\n",
      "capitu !\n",
      "\n",
      "\n",
      "[INFO] Generating text with \"Bentinho\" as prefix...\n",
      "bentinho ?\n",
      "\n",
      "bentinho , e certo que nao restabelecemos logo a vida .\n",
      "\n",
      "bentinho ?\n",
      "\n",
      "bentinho , mas eu nao queria ouvir o que a\n",
      "\n",
      "bentinho , mas o momento da hora e o trem da\n",
      "\n",
      "\n",
      "[INFO] Generating text with \"Escobar\" as prefix...\n",
      "escobar , e um gesto , mas o furor na sala , sem ver se\n",
      "\n",
      "escobar , e o gesto foi sempre a missa .\n",
      "\n",
      "escobar , como nos , e a morte , esperando que a pessoa que me levou o cao ao resto , me\n",
      "\n",
      "escobar , e o gesto nao era seguro .\n",
      "\n",
      "escobar , e eu nao desci os novos . o que e via o\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Generating text with \"Capitu \" as prefix...')\n",
    "model_1.generate(5, prefix=\"Capitu\")\n",
    "\n",
    "print('\\n[INFO] Generating text with \"Bentinho\" as prefix...')\n",
    "model_1.generate(5, prefix=\"Bentinho\")\n",
    "\n",
    "print('\\n[INFO] Generating text with \"Escobar\" as prefix...')\n",
    "model_1.generate(5, prefix=\"Escobar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
